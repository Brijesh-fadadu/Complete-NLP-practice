{"cells":[{"cell_type":"markdown","metadata":{"id":"wyT1tvEcgLV4"},"source":["# Sentence Segmentation\n","In **spaCy Basics** we saw briefly how Doc objects are divided into sentences. In this section we'll learn how sentence segmentation works, and how to set our own segmentation rules."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"iGLXRczRgLV5","executionInfo":{"status":"ok","timestamp":1658755029958,"user_tz":-330,"elapsed":9496,"user":{"displayName":"Brijesh Fadadu","userId":"17045474612112177029"}}},"outputs":[],"source":["# Perform standard imports\n","import spacy\n","nlp = spacy.load('en_core_web_sm')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WRONBMbAgLV6","executionInfo":{"status":"ok","timestamp":1658755038015,"user_tz":-330,"elapsed":593,"user":{"displayName":"Brijesh Fadadu","userId":"17045474612112177029"}},"outputId":"611d0819-47c3-448f-c289-7b2eb476368b"},"outputs":[{"output_type":"stream","name":"stdout","text":["This is the first sentence.\n","This is another sentence.\n","This is the last sentence.\n"]}],"source":["# From Spacy Basics:\n","doc = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')\n","\n","for sent in doc.sents:\n","    print(sent)"]},{"cell_type":"markdown","metadata":{"id":"v6rtmZiegLV6"},"source":["### `Doc.sents` is a generator\n","It is important to note that `doc.sents` is a *generator*. That is, a Doc is not segmented until `doc.sents` is called. This means that, where you could print the second Doc token with `print(doc[1])`, you can't call the \"second Doc sentence\" with `print(doc.sents[1])`:"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WEjrj9hcgLV7","executionInfo":{"status":"ok","timestamp":1658755077417,"user_tz":-330,"elapsed":633,"user":{"displayName":"Brijesh Fadadu","userId":"17045474612112177029"}},"outputId":"869e3d58-043d-41f9-d6cb-bf79bede0a2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["is\n"]}],"source":["print(doc[1])"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165},"id":"00WV8WRIgLV7","executionInfo":{"status":"error","timestamp":1658755081264,"user_tz":-330,"elapsed":968,"user":{"displayName":"Brijesh Fadadu","userId":"17045474612112177029"}},"outputId":"5b14d777-d61a-4da1-bedf-5f1acb670f9a"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-2bc012eee1da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"]}],"source":["print(doc.sents[1])"]},{"cell_type":"markdown","metadata":{"id":"Eo0tDXI3gLV7"},"source":["However, you *can* build a sentence collection by running `doc.sents` and saving the result to a list:"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6VS5NldngLV8","executionInfo":{"status":"ok","timestamp":1658755093000,"user_tz":-330,"elapsed":585,"user":{"displayName":"Brijesh Fadadu","userId":"17045474612112177029"}},"outputId":"9e019204-440c-4ee5-d2a8-5646a950307c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[This is the first sentence.,\n"," This is another sentence.,\n"," This is the last sentence.]"]},"metadata":{},"execution_count":5}],"source":["doc_sents = [sent for sent in doc.sents]\n","doc_sents"]},{"cell_type":"markdown","metadata":{"id":"UYrhlCtJgLV8"},"source":["<font color=green>**NOTE**: `list(doc.sents)` also works. We show a list comprehension as it allows you to pass in conditionals.</font>"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xDiMgJx4gLV8","executionInfo":{"status":"ok","timestamp":1658755104754,"user_tz":-330,"elapsed":526,"user":{"displayName":"Brijesh Fadadu","userId":"17045474612112177029"}},"outputId":"ec1a7bde-0aa8-4d02-873e-04b7e5e05eb2"},"outputs":[{"output_type":"stream","name":"stdout","text":["This is another sentence.\n"]}],"source":["# Now you can access individual sentences:\n","print(doc_sents[1])"]},{"cell_type":"markdown","metadata":{"id":"do5eMivsgLV9"},"source":["### `sents` are Spans\n","At first glance it looks like each `sent` contains text from the original Doc object. In fact they're just Spans with start and end token pointers."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a54E0vSdgLV9","executionInfo":{"status":"ok","timestamp":1658755125103,"user_tz":-330,"elapsed":636,"user":{"displayName":"Brijesh Fadadu","userId":"17045474612112177029"}},"outputId":"019ea39e-ddfc-48b1-c710-e6670c4850e3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["spacy.tokens.span.Span"]},"metadata":{},"execution_count":7}],"source":["type(doc_sents[1])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j259Ln7PgLV9","executionInfo":{"status":"ok","timestamp":1658755125676,"user_tz":-330,"elapsed":2,"user":{"displayName":"Brijesh Fadadu","userId":"17045474612112177029"}},"outputId":"c07b6960-871b-4888-f97c-e35a5d5a40dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["6 11\n"]}],"source":["print(doc_sents[1].start, doc_sents[1].end)"]},{"cell_type":"markdown","metadata":{"id":"um4fdCD0gLV9"},"source":["## Adding Rules\n","spaCy's built-in `sentencizer` relies on the dependency parse and end-of-sentence punctuation to determine segmentation rules. We can add rules of our own, but they have to be added *before* the creation of the Doc object, as that is where the parsing of segment start tokens happens:"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZib3ZwQgLV-","executionInfo":{"status":"ok","timestamp":1658755168305,"user_tz":-330,"elapsed":645,"user":{"displayName":"Brijesh Fadadu","userId":"17045474612112177029"}},"outputId":"75898ffa-f1e7-4dfe-e868-e3435bb4303e"},"outputs":[{"output_type":"stream","name":"stdout","text":["True  This\n","False  is\n","False  a\n","False  sentence\n","False  .\n","True  This\n","False  is\n","False  a\n","False  sentence\n","False  .\n","True  This\n","False  is\n","False  a\n","False  sentence\n","False  .\n"]}],"source":["# Parsing the segmentation start tokens happens during the nlp pipeline\n","doc2 = nlp(u'This is a sentence. This is a sentence. This is a sentence.')\n","\n","for token in doc2:\n","    print(token.is_sent_start, ' '+token.text)"]},{"cell_type":"markdown","metadata":{"id":"q521OEyrgLV-"},"source":["<font color=green>Notice we haven't run `doc2.sents`, and yet `token.is_sent_start` was set to True on two tokens in the Doc.</font>"]},{"cell_type":"markdown","metadata":{"id":"UNsYEU3JgLV-"},"source":["Let's add a semicolon to our existing segmentation rules. That is, whenever the sentencizer encounters a semicolon, the next token should start a new segment."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GpWjhekIgLV-","executionInfo":{"status":"ok","timestamp":1658755190531,"user_tz":-330,"elapsed":594,"user":{"displayName":"Brijesh Fadadu","userId":"17045474612112177029"}},"outputId":"36a04135-a934-4507-a16f-5a61def0483e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\"Management is doing things right; leadership is doing the right things.\"\n","-Peter Drucker\n"]}],"source":["# SPACY'S DEFAULT BEHAVIOR\n","doc3 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n","\n","for sent in doc3.sents:\n","    print(sent)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"fURB0zWwgLV-","executionInfo":{"status":"error","timestamp":1658757582576,"user_tz":-330,"elapsed":12,"user":{"displayName":"Brijesh Fadadu","userId":"17045474612112177029"}},"outputId":"8ed73861-34c4-4245-a111-bf6076c52695"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-16e91b00ce09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mruler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEntityRuler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mruler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_custom_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/pipeline/entityruler.py\u001b[0m in \u001b[0;36madd_patterns\u001b[0;34m(self, patterns)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mphrase_pattern_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mphrase_pattern_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pattern\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                     \u001b[0mphrase_pattern_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'function' object is not iterable"]}],"source":["from spacy.pipeline import EntityRuler\n","\n","# ADD A NEW RULE TO THE PIPELINE\n","def set_custom_boundaries(doc):\n","    for token in doc[:-1]:\n","        if token.text == ';':\n","            doc[token.i+1].is_sent_start = True\n","    return doc\n","\n","#nlp.add_pipe(set_custom_boundaries, before='parser')\n","\n","#nlp.pipe_names\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JzszdVwwgLV_"},"source":["<font color=green>The new rule has to run before the document is parsed. Here we can either pass the argument `before='parser'` or `first=True`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CS9Uls7fgLV_","outputId":"5ab48a5c-a72e-45f2-995a-3f332ce68441"},"outputs":[{"name":"stdout","output_type":"stream","text":["\"Management is doing things right;\n","leadership is doing the right things.\"\n","-Peter Drucker\n"]}],"source":["# Re-run the Doc object creation:\n","doc4 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n","\n","for sent in doc4.sents:\n","    print(sent)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yos7u8u-gLV_","outputId":"4f6e4437-586c-40ce-bf9c-7e6483154dd9"},"outputs":[{"name":"stdout","output_type":"stream","text":["\"Management is doing things right; leadership is doing the right things.\"\n","-Peter Drucker\n"]}],"source":["# And yet the new rule doesn't apply to the older Doc object:\n","for sent in doc3.sents:\n","    print(sent)"]},{"cell_type":"markdown","metadata":{"id":"x6fNsbA2gLV_"},"source":["### Why not change the token directly?\n","Why not simply set the `.is_sent_start` value to True on existing tokens?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gC6L0flVgLWA","outputId":"ab121833-2b75-48a1-abf2-247c0325b0a4"},"outputs":[{"data":{"text/plain":["leadership"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Find the token we want to change:\n","doc3[7]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8hAMVRjsgLWA","outputId":"06281815-5c0a-4a91-bb6b-64b91d332ff2"},"outputs":[{"ename":"ValueError","evalue":"[E043] Refusing to write to token.sent_start if its document is parsed, because this may cause inconsistent state.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-5-bcec3fe6a9a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Try to change the .is_sent_start attribute:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdoc3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sent_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mtoken.pyx\u001b[0m in \u001b[0;36mspacy.tokens.token.Token.is_sent_start.__set__\u001b[1;34m()\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: [E043] Refusing to write to token.sent_start if its document is parsed, because this may cause inconsistent state."]}],"source":["# Try to change the .is_sent_start attribute:\n","doc3[7].is_sent_start = True"]},{"cell_type":"markdown","metadata":{"id":"w3ApElNCgLWA"},"source":["<font color=green>spaCy refuses to change the tag after the document is parsed to prevent inconsistencies in the data.</font>"]},{"cell_type":"markdown","metadata":{"id":"WrHnYXIegLWA"},"source":["## Changing the Rules\n","In some cases we want to *replace* spaCy's default sentencizer with our own set of rules. In this section we'll see how the default sentencizer breaks on periods. We'll then replace this behavior with a sentencizer that breaks on linebreaks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-ngUJTAgLWA","outputId":"c1b64dad-3522-4772-9f96-c208b3c1c166"},"outputs":[{"name":"stdout","output_type":"stream","text":["['This', 'is', 'a', 'sentence', '.']\n","['This', 'is', 'another', '.', '\\n\\n']\n","['This', 'is', 'a', '\\n', 'third', 'sentence', '.']\n"]}],"source":["nlp = spacy.load('en_core_web_sm')  # reset to the original\n","\n","mystring = u\"This is a sentence. This is another.\\n\\nThis is a \\nthird sentence.\"\n","\n","# SPACY DEFAULT BEHAVIOR:\n","doc = nlp(mystring)\n","\n","for sent in doc.sents:\n","    print([token.text for token in sent])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_I1a1sA-gLWA"},"outputs":[],"source":["# CHANGING THE RULES\n","from spacy.pipeline import SentenceSegmenter\n","\n","def split_on_newlines(doc):\n","    start = 0\n","    seen_newline = False\n","    for word in doc:\n","        if seen_newline:\n","            yield doc[start:word.i]\n","            start = word.i\n","            seen_newline = False\n","        elif word.text.startswith('\\n'): # handles multiple occurrences\n","            seen_newline = True\n","    yield doc[start:]      # handles the last group of tokens\n","\n","\n","sbd = SentenceSegmenter(nlp.vocab, strategy=split_on_newlines)\n","nlp.add_pipe(sbd)"]},{"cell_type":"markdown","metadata":{"id":"ijer_41egLWA"},"source":["<font color=green>While the function `split_on_newlines` can be named anything we want, it's important to use the name `sbd` for the SentenceSegmenter.</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v5WUO7nZgLWA","outputId":"1b7c0ee6-818a-46cf-eedf-994d0949b1ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["['This', 'is', 'a', 'sentence', '.', 'This', 'is', 'another', '.', '\\n\\n']\n","['This', 'is', 'a', '\\n']\n","['third', 'sentence', '.']\n"]}],"source":["doc = nlp(mystring)\n","for sent in doc.sents:\n","    print([token.text for token in sent])"]},{"cell_type":"markdown","metadata":{"id":"X-sBNtPXgLWA"},"source":["<font color=green>Here we see that periods no longer affect segmentation, only linebreaks do. This would be appropriate when working with a long list of tweets, for instance.</font>\n","## Next Up: POS Assessment"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"04-Sentence-Segmentation.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}